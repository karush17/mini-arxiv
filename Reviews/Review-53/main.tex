
\documentclass[11pt,letterpaper]{article}
\usepackage{fullpage}
\usepackage[top=2cm, bottom=4.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\hypersetup{%
  colorlinks=true,
  linkcolor=blue,
  linkbordercolor={0 0 1}
}
\renewcommand\lstlistingname{Algorithm}
\renewcommand\lstlistlistingname{Algorithms}
\def\lstlistingautorefname{Alg.}

\lstdefinestyle{Python}{
    language        = Python,
    frame           = lines, 
    basicstyle      = \footnotesize,
    keywordstyle    = \color{blue},
    stringstyle     = \color{green},
    commentstyle    = \color{red}\ttfamily
}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}



\pagestyle{fancyplain}
\headheight 35pt
                 % ENTER REVIEW NUMBER HERE %
\chead{\textbf{\large Review-53}}
           % ################################### %

\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\begin{document}


                 % ENTER PAPER TITLE HERE %
\begin{center}
  \large{On the mapping between Hopfield networks and Restricted Boltzmann Machines}
\end{center}
           % ################################### %

Hopfield Networks (HNs) and Restricted Boltzmann Machines (RBMs) are subjects of extensive studies in various computational arenas. Prior work has presented an exact mapping between HNs and RBMs in the case of uncorrelated patterns. The paper presents an exact mapping between the two models in the case of correlated patterns which are of broader interest to modern datasets. Towards this goal, the work highlights that any HN with patterns $p < N$ binary variables can be transformed into an RBM with $N$ binary visible variables and $p$ gaussian hidden variables. An additional reverse mapping is established using tractable approximations with experiments on MNIST dataset depicting the efficacy of mapping as a suitable parameter initialization for RBM.

The work establishes an exact mapping between HNs and RBMs which are regarded as spin glass models with energy-based update rules. While the former is primarily an associative memory with Hebbian rule, the latter is used for generative modelling utilizing visible-hidden interactions. The mapping from HN to RBM consists of orthogonalizing the patterns using a $QR$ decomposition $\xi = QR$ with $Q$ being the orthogonalized patterns and $R$ being an upper-triangular mapping matrix. More generally, any orthogonal mapping (such as SVD $\xi = U\Sigma V^{T}$) can be utilized to orthogonalize the patterns. Orthogonality simplifies the interaction matrix to a conventional Hebbian rule $J = QQ^{T}$. Further utilizing $q(s) = Q^{T}s$ in Hamiltonian $H(s)$ and rewriting the partition function using Gauss integral allows one to see the obtained expression as the partition function of an expanded Hamiltonian akin to an RBM $H(\{s_{i}\},\{\lambda_{\mu}\})$. An alternate procedure to arrive at the result is to marginalize out the original variables $\{s_{i}\}$ and see the energy function $F_{0}(\lambda)$ as an expression for the dynamics of RBM interactions. The inverse mapping from RBM to HN, on the other hand, consists of realizing the pairwise spin glass structure of RBM as an Ising model. Since the trained parameters of an RBM may not be binary, RBM interactions can extend towards the complex plane. To alleviate this problem, the inverse mapping seeks an invertible transformation $X$ which binarizes $W$. Intuitively, the mapping approximates the transformation $B_{p} = WX$. 

Hopfield mapping demonstrates suitable initializations for RBM parameters. The mechanism results in suitable maximization of likelihood with varying sub-patterns and temperature values which is further validated in the conventional RBM training. Hopfield initialization performs significantly well in comparison to the conventional random and PCA initializations, a common practice in deep learning. Additionaly, samples generated by Hopfield initialized RBM within initial epochs of training are found qualitatively similar to true pixel arrangements. This is further validated from the associative memory perspective in the case of inverse mapping. On the other hand, the work does not throw light on complex interactions in the case of deeper RBMs which is observed by a second application of Gauss integral in the "Overlap" BM. 

Towards a theoretically rich connection between HNs and RBMs, the work introduces two new directions for future research. Firstly, the work can be extended to obtain alternate mappings between deeper RBMs and Belief Nets. And secondly, the mapping could be studied for the more pragmatic non-binary pattern settings in light of Modern HNs with continuous inputs.

The work proposes to map a HN on to an RBM by utilizing the orthogonal decomposition of patterns in the binary setting. Following an RBM Hamiltonian $H_{RBM}$, a reverse mapping can be obtained by approximating an invertible transformation in order to binarize the pattern encodings. Hopfield initialized RBMs demonstrate improved parameter initialization with generated samples qualitatively resembling original data. 

\end{document}
