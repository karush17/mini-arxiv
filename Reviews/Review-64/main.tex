
\documentclass[11pt,letterpaper]{article}
\usepackage{fullpage}
\usepackage[top=2cm, bottom=4.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\hypersetup{%
  colorlinks=true,
  linkcolor=blue,
  linkbordercolor={0 0 1}
}
\renewcommand\lstlistingname{Algorithm}
\renewcommand\lstlistlistingname{Algorithms}
\def\lstlistingautorefname{Alg.}

\lstdefinestyle{Python}{
    language        = Python,
    frame           = lines, 
    basicstyle      = \footnotesize,
    keywordstyle    = \color{blue},
    stringstyle     = \color{green},
    commentstyle    = \color{red}\ttfamily
}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}



\pagestyle{fancyplain}
\headheight 35pt
                 % ENTER REVIEW NUMBER HERE %
\chead{\textbf{\large Review-64}}
           % ################################### %

\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\begin{document}


                 % ENTER PAPER TITLE HERE %
\begin{center}
  \large{Fully Unsupervised Diversity Denoising with Convolutional Variational Autoencoders}
\end{center}
           % ################################### %


Image restoration is the problem of faithfully acquiring an image sample from its corrupted counterpart. Prior image restoration methods borrow from deep learning in order to improve the interpretability of data. However, these methods often fall prey to limited efficacy in Content-Aware Image Restoration (CARE). The work introduces DivNoising, a denoising method based on fully unsupervised convolutional variational autoencoders. DivNoising overcomes the problem of single solution prediction by predicting the whole distribution of denoised images. The pipeline requires noisy images and a suitable description of the noise distribution, based on which consensus predictions are inferred from a set of DivNoising predictions. The proposed method establishes image restoration competitive to state-of-the-art and effectiveness in downstream tasks. 

At its core, DivNoising proposes a way to co-learn a suitable noise model during training. The method departs from commiting to a single prediction and outputs a distribution over denoised images. This is achieved by factorizing the noise model into its independent components $p_{NM}(x|s) = \prod_{i}^{N}p_{NM}(x_{i}|s_{i})$. Such a factorization gives rise to the joint distribution over latents, noisy inputs and signals as $p(z,x,s) = p_{NM}(x|s)p(s|z)p(z)$ representing the decoder of the VAE. The clean signal $s$ is deterministically defined as a result of which, $p(s|z)$ corresponds to a Dirac distribution. The pixel noise model $p_{NM}$ may be measured, bootstrapped or co-learned in the fully unspuervised VAE training. Following training, the prediction phase samples $s$ from an approximate posterior, feeds the noisy input $x$ to the encoder, draws $z \sim q(z|x)$ and decodes samples $s = g_{\theta}(z)$ using the parameterized decoder $g_{\theta}$. One can further estimate different consensus (point estimates) from samples $s$ such as MMSE or MAP estimates corresponding to noisy observations $x$.

DivNoising demonstrates improved image restoration qualitatively and quantitatively (expressed as Signal-Noise ratio) on a wide variety of datasets. The method is found competitive to state-of-the-art supervised baselines and outperforms prior unsupervised methods in literature. Accuracy of the co-learned noise model is further validated by observing its small deviation from the measured noisy estimates. DivNoising additionally presents applications in downstream segmentation wherein the approach accurately segments complex regions of cell structures in comparison to conventional approaches utilizing local thresholding and skeletonization. However, the work may be better motivated with regards to its imaging noise. A primary assumption upon which the method relies is that of independently occuring corruptions in the input signal. The assumption holds true for Poission shot noise and camera readout noise. On the other hand, most corrupted images may arise from other sources of noise such as Gaussian or Salt-Pepper noise. Perhaps the work could better reason about its efficacy under alternate noise models. Additionally, the study could feature more datasets or fine-grained cell structures which are non-trivial to segment in practice. 

Introduction of a fully unspervised denoising approach with applications to downstream learning opens several new avenues for future research. Firstly, the work may be extended to include other real-world datasets ranging from high resolution videography to geographical imaging as these consist of more complex noise models. And secondly, it would be interesting to study the efficacy of DivNoising in noise sample dependent settings. The latter could help explain image denoising under complex corruption schemes. 

The paper introduced DivNoising, a fully unspervised denoising scheme which lifts the restriction on single-step prediction and allows the model to output a distribution over denoising images. DivNoising demonstrates efficient image restoration and downstream segmentation. 
\end{document}
