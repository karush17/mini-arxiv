
\documentclass[12pt,letterpaper]{article}
\usepackage{fullpage}
\usepackage[top=2cm, bottom=4.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\hypersetup{%
  colorlinks=true,
  linkcolor=blue,
  linkbordercolor={0 0 1}
}
\renewcommand\lstlistingname{Algorithm}
\renewcommand\lstlistlistingname{Algorithms}
\def\lstlistingautorefname{Alg.}

\lstdefinestyle{Python}{
    language        = Python,
    frame           = lines, 
    basicstyle      = \footnotesize,
    keywordstyle    = \color{blue},
    stringstyle     = \color{green},
    commentstyle    = \color{red}\ttfamily
}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}



\pagestyle{fancyplain}
\headheight 35pt
                 % ENTER REVIEW NUMBER HERE %
\chead{\textbf{\large Review-66}}
           % ################################### %

\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\begin{document}


                 % ENTER PAPER TITLE HERE %
\begin{center}
  \large{High-Dimensional Bayesian Optimization
  via Nested Riemannian Manifolds}
\end{center}
           % ################################### %

The success of Bayesian Optimization (BO) is hindered by high-dimensional parameter sapces. An alternate to this problem is to induce domain knowledge into the formulation. The work proposes to exploit the geometry of non-Euclidean search spaces in order to learn structure-preserving mappings in low-dimensional latent spaces. The paper focusses on geomtry-aware Gaussian Processes that jointly learn a nested manifold embedding and a representation of the objective function in latent space. High-Dimensional Geomtry-aware BO (HDGaBO) outperformas prior BO methods and consistently optimizes objective functions.

Various real world scenarios only require the use of low-dimensional search space which is often found embedded in a high-dimensional geometric structure. For instance, while a pushing a block of mass radially, a robot arm only utilizes the cartesian space which is contained in the high-dimensional manifold structure. The work borrows from this insight and optimizes parameters lying on low-dimensional Riemannian manifolds embedded in high-dimensional spaces. The latent spaces are obtained via nested projections in parameteric structure-preserving mappings. The parameters $\theta_{m}$ and $\theta_{g}$ of the mapping $m$ and function $g$ are determined in a supervised manner using Gaussian processes. An inverse mapping $m^{\dag}$, which is the pseudo-inverse of $m$, reconstructs the parameters which are thus designed to minimize the reconstruction error. The data samples $x_{i}$ are projected to the latent space $z_{i} = m(x_{i})$ wherein the next query point $z_{n+1}$ is selected by optimizing the acquisition function in the latent space. Following parameter updates, the query point is projected back to the original space $x_{n+1} = m^{\dag}(z_{n+1})$ to obtain $y_{n+1}$ and augment the observed data $\mathcal{D}_{n+1}$. The mapping $m$ serves as a structure-preserving nestedmapping from the high-dimensional manifold $\mathcal{M}_{D}$ to the low-dimensional manifold $\mathcal{M}_{m}$. The reconstructions, on the other hand, are optimized by minimizing the sum of squared residuals on manifold $\mathcal{M}_{d}$.

HD-GaBO, when compared to other geomtry-aware BO methods on a range of challenging manifolds, better optimizes regret and depicts lower errors in its reconstructions. Even in the case of complex structures such as the product of sines, the proposed approach consistently optimizes its objective function in comparison to other technqiues which depict faster saturation. Additionally, the work highlights various directions related to robot control and dynamical system modelling as potential applications. However, the work does not demonstrate a solid empirical evaluation of HD-GaBO in nested manifolds. For instance, HD-GaBO could be evaluated in even high-dimensional spaces such as $S^{5}$ embedded in $S^{50}$ embedded in $S^{100}$. Along similar lines, it is natural to ask the behavior of nested mapping and reconstructions when the number of dimensions are varied. Pursuing the above two directions for future work would help better understand the efficacy and limitations of geometry-aware BO in high-dimensional spaces.



\end{document}
